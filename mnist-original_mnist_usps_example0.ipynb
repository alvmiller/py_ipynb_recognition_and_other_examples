{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53d3c8-e6a4-4814-b9ee-79c915438436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/avnishnish/mnist-original\n",
    "# https://github.com/LukasHedegaard/mnist-usps\n",
    "# https://www.digitalocean.com/community/tutorials/mnist-dataset-in-python\n",
    "# https://www.geeksforgeeks.org/machine-learning/mnist-dataset/\n",
    "# https://medium.com/@muhammetbolat/supervised-unsupervised-techniques-on-mnist-dataset-3f2ffd4c41c5\n",
    "# https://mangohost.net/blog/mnist-dataset-in-python-machine-learning-example/\n",
    "# https://anirudhdaya.hashnode.dev/building-a-convolutional-neural-network-for-handwritten-digit-recognition\n",
    "# https://datasets-dev.10web.me/docs/ml/datasets/usps-dataset/\n",
    "# https://www.linkedin.com/pulse/deep-learning-project-mnist-handwritten-digits-guide-fazle-rabbi-qwowc\n",
    "# https://datasets.activeloop.ai/docs/ml/datasets/mnist/\n",
    "# https://medium.com/@azimkhan8018/a-beginners-guide-to-deep-learning-with-mnist-dataset-0894f7183344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00eba21-b464-4b0f-9232-5cff356c2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab2180b-3dd0-4fc7-9936-ae54598b608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#loading the dataset\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "#printing the shapes of the vectors \n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce2c882-620d-449c-b980-0bf874db4a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 2 (955722700.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpyplot.subplot(330 + 1 + i)\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'for' statement on line 2\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "for i in range(9):  \n",
    "pyplot.subplot(330 + 1 + i)\n",
    "pyplot.imshow(train_X[i], cmap=pyplot.get_cmap('gray'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79821dae-4316-4973-92c3-f781e7c98b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed6cbb2-c90f-40b8-8199-4d4971f07b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "# Print 4 images in a row\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c15621-d7d5-4652-b176-09dfbce2dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:01<00:00, 7.07MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 227kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:00<00:00, 1.99MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transformation to convert images to PyTorch tensors\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the MNIST dataset with the specified transformation\n",
    "mnist_pytorch = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a DataLoader to load the dataset in batches\n",
    "train_loader_pytorch = torch.utils.data.DataLoader(mnist_pytorch, batch_size=1, shuffle=False)\n",
    "\n",
    "# Create a figure to display the images\n",
    "plt.figure(figsize=(15, 3))\n",
    "\n",
    "# Print the first few images in a row\n",
    "for i, (image, label) in enumerate(train_loader_pytorch):\n",
    "    if i < 5:  # Print the first 5 samples\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(image[0].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Label: {label.item()}\")\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        break  # Exit the loop after printing 5 samples\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99badd-c4be-46cd-bcd1-10b5e5c205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beaabd51-408e-4389-8db3-dcd2167826e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "barplot() takes from 0 to 1 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m value_count_training = collections.Counter(training_dataset_y)\n\u001b[32m     10\u001b[39m fig, ax0 = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, dpi=\u001b[32m100\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m ax = \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue_count_training\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue_count_training\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcool\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m ax.set_xlabel(\u001b[33m'\u001b[39m\u001b[33mHandwritten Numbers\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m ax.set_title(\u001b[33m\"\u001b[39m\u001b[33mNumbers Distribution\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: barplot() takes from 0 to 1 positional arguments but 2 positional arguments (and 1 keyword-only argument) were given"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist;\n",
    "\n",
    "(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "value_count_training = collections.Counter(training_dataset_y)\n",
    "\n",
    "fig, ax0 = plt.subplots(1, 1, dpi=100)\n",
    "ax = sns.barplot(list(value_count_training.keys()), list(value_count_training.values()), palette='cool')\n",
    "ax.set_xlabel('Handwritten Numbers')\n",
    "ax.set_title(\"Numbers Distribution\")\n",
    "plt.show();\n",
    "training_dataset_x = training_dataset_x.reshape(-1, 28 * 28) \n",
    "test_dataset_x = test_dataset_x.reshape(-1, 28 * 28)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "training_dataset_y = to_categorical(training_dataset_y)\n",
    "test_dataset_y = to_categorical(test_dataset_y)\n",
    "\n",
    "training_dataset_x = training_dataset_x / 255\n",
    "test_dataset_x = test_dataset_x / 255\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=28 * 28, activation='relu', name='Hidden-1'))\n",
    "model.add(Dense(256, activation='relu', name='Hidden-2'))\n",
    "model.add(Dense(10, activation='softmax', name='Output'))\n",
    "\n",
    "loss, accuracy = model.evaluate(test_dataset_x, test_dataset_y)\n",
    "print('loss = {}, accuracy = {}'.format(loss, accuracy))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Epoch-Accuracy Graph')\n",
    "plt.xlabel = 'Epochs'\n",
    "plt.ylabel = 'Loss'\n",
    "plt.plot(range(1, len(hist.epoch) + 1), hist.history['accuracy'])\n",
    "plt.plot(range(1, len(hist.epoch) + 1), hist.history['val_accuracy'])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()\n",
    "\n",
    "training_dataset_x = training_dataset_x.reshape(-1, 28, 28, 1)\n",
    "test_dataset_x = test_dataset_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "training_dataset_x = training_dataset_x.astype('float32')\n",
    "test_dataset_x = test_dataset_x.astype('float32')\n",
    "\n",
    "training_dataset_x /= 255\n",
    "test_dataset_x /= 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "training_dataset_y = to_categorical(training_dataset_y)\n",
    "test_dataset_y = to_categorical(test_dataset_y)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu', name='Convolution-1'))\n",
    "model.add(MaxPooling2D(name='MaxPooling2D-1'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name='Convolution-2'))\n",
    "model.add(MaxPooling2D(name='MaxPooling2D-2'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='Hidden-1'))\n",
    "model.add(Dense(128, activation='relu', name='Hidden-2'))\n",
    "model.add(Dense(10, activation='softmax', name='Output'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "loss, accuracy = model.evaluate(test_dataset_x, test_dataset_y)\n",
    "print('loss = {}, accuracy = {}'.format(loss, accuracy))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Epoch-Accuracy Graph')\n",
    "plt.xlabel = 'Epochs'\n",
    "plt.ylabel = 'Loss'\n",
    "plt.plot(range(1, len(hist.epoch) + 1), hist.history['accuracy'])\n",
    "plt.plot(range(1, len(hist.epoch) + 1), hist.history['val_accuracy'])\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.show()\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random as rn\n",
    "\n",
    "# Visualization libraries\n",
    "import pydotplus\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style({\"axes.facecolor\": \".95\"})\n",
    "\n",
    "# Modeling and Machine Learning\n",
    "from IPython.display import Image \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "# Seed for reproducability\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def acc(y_true : np.ndarray, y_pred : np.ndarray) -> float: return round(accuracy_score(y_true, y_pred) * 100, 2)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()\n",
    "\n",
    "training_dataset_x = training_dataset_x.reshape(-1, 28, 28, 1)\n",
    "test_dataset_x = test_dataset_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "training_dataset_x = training_dataset_x.astype('float32')\n",
    "test_dataset_x = test_dataset_x.astype('float32')\n",
    "\n",
    "training_dataset_x = training_dataset_x.reshape(-1, 28*28)\n",
    "test_dataset_x = test_dataset_x.reshape(-1, 28*28)\n",
    "\n",
    "# Train baseline decision tree model\n",
    "clf = DecisionTreeClassifier(max_depth=30, random_state=seed)\n",
    "%time clf.fit(training_dataset_x, training_dataset_y)\n",
    "\n",
    "training_pred_result_clf = clf.predict(training_dataset_x)\n",
    "test_pred_result_clf = clf.predict(test_dataset_x)\n",
    "\n",
    "training_sccuracy = (training_dataset_y == training_pred_result_clf).sum() / len(training_dataset_y)\n",
    "test_sccuracy = (test_dataset_y == test_pred_result_clf).sum() / len(test_dataset_y)\n",
    "\n",
    "print(\"Training accuracy for our baseline (using all pixel features): {}\".format(training_sccuracy))\n",
    "print(\"Validation accuracy for our baseline (using all pixel features): {}\".format(test_sccuracy))\n",
    "\n",
    "# Convert Decision Tree to visualization\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True, \n",
    "                max_depth=3)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "\n",
    "# Create PNG file\n",
    "Image(graph.create_png())\n",
    "\n",
    "(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()\n",
    "# Evaluate the baseline model\n",
    "train_preds_baseline = clf.predict(training_dataset_x.reshape(-1, 28*28))\n",
    "val_preds_baseline = clf.predict(test_dataset_x.reshape(-1, 28*28))\n",
    "acc_baseline_train = acc(train_preds_baseline, training_dataset_y)\n",
    "acc_baseline_val = acc(val_preds_baseline, test_dataset_y)\n",
    "print(f'Training accuracy for our baseline (using all pixel features): {acc_baseline_train}%')\n",
    "print(f'Validation accuracy for our baseline (using all pixel features): {acc_baseline_val}%')\n",
    "\n",
    "tsvd = TruncatedSVD(n_components=50).fit_transform(training_dataset_x.reshape(-1, 28*28))\n",
    "clf = DecisionTreeClassifier(max_depth=30, random_state=seed)\n",
    "%time clf.fit(tsvd[:50000], training_dataset_y[:50000])\n",
    "\n",
    "# Evaluate model with the 50 TSVD features and compare to the baseline model\n",
    "train_preds = clf.predict(tsvd[:50000])\n",
    "val_preds = clf.predict(tsvd[50000:])\n",
    "acc_tsvd_train = acc(train_preds, training_dataset_y[:50000])\n",
    "acc_tsvd_val = acc(val_preds, training_dataset_y[50000:])\n",
    "print(f'Training accuracy with TSVD features (50 components): {acc_tsvd_train}%')\n",
    "print(f'Validation accuracy with TSVD features (50 components): {acc_tsvd_val}%')\n",
    "# Check out how it performed compared to the baseline\n",
    "acc_diff = round(acc_tsvd_val - acc_baseline_val, 2)\n",
    "print(f'\\nThis is a difference of {acc_diff}% in validation accuracy compared to the baseline.')\n",
    "\n",
    "# Fit t-SNE on the Truncated SVD reduced data (50 features)\n",
    "tsne = TSNE()\n",
    "%time transformed = tsne.fit_transform(tsvd)\n",
    "# Split up the t-SNE results in training and testing data\n",
    "tsne_train = pd.DataFrame(transformed[:50000], columns=['component1', 'component2'])\n",
    "tsne_test = pd.DataFrame(transformed[50000:], columns=['component1', 'component2'])\n",
    "\n",
    "# Visualize the results for t-SNE on MNIST\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.title(f\"Visualization of t-SNE results on the MNIST Dataset\\n\\\n",
    "Amount of datapoints: {len(tsne_train)}\", fontsize=24, weight='bold')\n",
    "sns.scatterplot(\"component1\", \"component2\", \n",
    "                data=tsne_train, hue=training_dataset_y[:50000], \n",
    "                palette=\"Set1\", legend=\"full\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=16);\n",
    "\n",
    "# Perform another split for t-sne feature validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(tsne_train, \n",
    "                                                training_dataset_y[:50000], test_size=0.25, random_state=seed)\n",
    "\n",
    "# Train model with t-sne features\n",
    "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Save the decision tree slice as PNG\n",
    "graph.write_png(\"mnist_decision_tree_tsne.png\");\n",
    "Image(graph.create_png())\n",
    "\n",
    "# Evaluate model with t-SNE features and compare to the baseline model\n",
    "train_preds = clf.predict(X_train)\n",
    "val_preds = clf.predict(X_val)\n",
    "acc_tsne_train = acc(train_preds, y_train)\n",
    "acc_tsne_val = acc(val_preds, y_val)\n",
    "print(f'Training accuracy with t-SNE features: {acc_tsne_train}%')\n",
    "print(f'Validation accuracy with t-SNE features: {acc_tsne_val}%')\n",
    "# Compare t-SNE results with the baseline model\n",
    "acc_diff = round(acc_tsne_val - acc_baseline_val, 2)\n",
    "print(f'\\nThis is an improvement of {acc_diff}% in validation accuracy over the baseline!')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()\n",
    "\n",
    "training_dataset_x = training_dataset_x.reshape(-1, 28 * 28)[:20000, :]\n",
    "training_dataset_y = training_dataset_y[:20000]\n",
    "test_dataset_x = test_dataset_x.reshape(-1, 28 * 28)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(verbose=2)\n",
    "lr.fit(training_dataset_x, training_dataset_y)\n",
    "lr_predict_result = lr.predict(test_dataset_x)\n",
    "print(\"Logistic Regression: Accuracy result is {}\".format((lr_predict_result == test_dataset_y).sum() / len(test_dataset_y)))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ratios = []\n",
    "optimal_feature = None\n",
    "for i in range(100):\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(training_dataset_x.reshape(-1, 28*28))\n",
    "    ratios.append(np.sum(pca.explained_variance_ratio_))\n",
    "    if not optimal_feature and ratios[-1] >= 0.80:\n",
    "        optimal_feature = i\n",
    "    print('{}---> {}'.format(i, ratios[-1]))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=784).fit(X_std)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(list(range(784)), pca.explained_variance_ratio_)\n",
    "plt.title(\"Single Variable's Exlained Variance\")\n",
    "\n",
    "# Determine explained variance of cumulative variables\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=784).fit(X_std)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(list(range(784)), pca.explained_variance_ratio_.cumsum())\n",
    "plt.title(\"Cumulative Variable's Exlained Variance\")\n",
    "\n",
    "data_x = training_dataset_x.copy()\n",
    "data_y = training_dataset_y.copy()\n",
    "\n",
    "val_data_x = test_dataset_x.copy()\n",
    "val_data_y = test_dataset_y.copy()\n",
    "\n",
    "pca_std = StandardScaler().fit_transform(data_x.reshape(-1, 28*28))\n",
    "\n",
    "# Call the PCA method with 2 components. \n",
    "pca = PCA(n_components=2)\n",
    "x_2 = pca.fit(pca_std).transform(pca_std)\n",
    "data = [go.Scatter(\n",
    "                    x = x_2[:,0],\n",
    "                    y = x_2[:,1],\n",
    "                    mode = 'markers',\n",
    "                    showlegend = False,\n",
    "                    marker = dict(\n",
    "                    size = 8,\n",
    "                    color = data_y,\n",
    "                    colorscale ='Rainbow',\n",
    "                    showscale = False,\n",
    "                    line = dict(\n",
    "                                width = 2,\n",
    "                                color = 'rgb(255, 255, 255)')\n",
    "                    ,\n",
    "        opacity = 0.8\n",
    "    )\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'Principal Component Analysis (PCA)',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "         title= 'First Principal Component',\n",
    "        ticklen= 8,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Second Principal Component',\n",
    "        ticklen= 8,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    showlegend= True\n",
    ")\n",
    "\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='PCA_plot')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# Set a KMeans clustering with 10 components cuz there are 9 class labels\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "# Compute cluster centers and predict cluster indices\n",
    "kmeans_10 = kmeans.fit_predict(x_2)\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x= x_2[:, 0], \n",
    "        y= x_2[:, 1], \n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color = kmeans_10,\n",
    "            colorscale = 'Rainbow',\n",
    "            showscale=False, \n",
    "            line = dict(\n",
    "                width = 2,\n",
    "                color = 'rgb(255, 255, 255)'\n",
    "            )))]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'KMeans Clustering',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "         title= 'First Principal Component',\n",
    "        ticklen= 8,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Second Principal Component',\n",
    "        ticklen= 8,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    showlegend= True\n",
    ")\n",
    "\n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename=\"kmeans_plot\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# Set a KMeans clustering with 10 components cuz there are 9 class labels\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "# Compute cluster centers and predict cluster indices\n",
    "kmeans_10 = kmeans.fit_predict(x_2)\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x= x_2[:, 0], \n",
    "        y= x_2[:, 1], \n",
    "        mode=\"markers\",\n",
    "        showlegend=False,\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color = kmeans_10,\n",
    "            colorscale = 'Rainbow',\n",
    "            showscale=False, \n",
    "            line = dict(\n",
    "                width = 2,\n",
    "                color = 'rgb(255, 255, 255)'\n",
    "            )))]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'KMeans Clustering',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "         title= 'First Principal Component',\n",
    "        ticklen= 8,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Second Principal Component',\n",
    "        ticklen= 8,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    showlegend= True\n",
    ")\n",
    "\n",
    "fig = dict(data = data, layout = layout)\n",
    "py.iplot(fig, filename=\"kmeans_plot\")\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=2)\n",
    "\n",
    "x_lda = lda.fit_transform(data_x.reshape(-1, 28*28), data_y)\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "    x = x_lda[:,0],\n",
    "    y = x_lda[:,1],\n",
    "    mode = 'markers',\n",
    "    showlegend = True,\n",
    "    marker = dict(\n",
    "        size = 8,\n",
    "        color = data_y,\n",
    "        colorscale ='Rainbow',\n",
    "        showscale = False,\n",
    "        opacity = 0.8,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(255, 255, 255)'\n",
    "        )\n",
    "    )\n",
    ")]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title= 'Linear Discriminant Analysis (LDA)',\n",
    "    hovermode= 'closest',\n",
    "    xaxis= dict(\n",
    "         title= 'First Linear Discriminant',\n",
    "        ticklen= 8,\n",
    "        zeroline= False,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title= 'Second Linear Discriminant',\n",
    "        ticklen= 8,\n",
    "        gridwidth= 2,\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='lda_plot')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# Invoking the t-SNE method\n",
    "tsne = TSNE()\n",
    "x_tsne = tsne.fit_transform(data_x[:20000].reshape(-1, 28*28))\n",
    "\n",
    "# Plot TSNE graph\n",
    "data = [\n",
    "    go.Scatter(\n",
    "    x = x_tsne[:,0],\n",
    "    y = x_tsne[:,1],\n",
    "    mode = 'markers',\n",
    "    showlegend = True,\n",
    "    marker = dict(\n",
    "        size = 8,\n",
    "        color = data_y,\n",
    "        colorscale ='Rainbow',\n",
    "        showscale = False,\n",
    "        opacity = 0.8,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(255, 255, 255)'\n",
    "        )\n",
    "    )\n",
    ")]\n",
    "\n",
    "layout = dict(title = 'TSNE (T-Distributed Stochastic Neighbour Embedding)',\n",
    "              hovermode= 'closest',\n",
    "              yaxis = dict(zeroline = False),\n",
    "              xaxis = dict(zeroline = False),\n",
    "              showlegend= False,\n",
    "\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='TSNE_plot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308a80f-46b5-4b4c-a45a-96137d684995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fbfa47-b690-4a61-91ff-4c00baf01dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2953 - val_accuracy: 0.9565 - val_loss: 0.1445\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1414 - val_accuracy: 0.9689 - val_loss: 0.1003\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.1064 - val_accuracy: 0.9727 - val_loss: 0.0897\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0843 - val_accuracy: 0.9769 - val_loss: 0.0746\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.0731 - val_accuracy: 0.9785 - val_loss: 0.0739\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0641 - val_accuracy: 0.9780 - val_loss: 0.0757\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0560 - val_accuracy: 0.9793 - val_loss: 0.0688\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0528 - val_accuracy: 0.9791 - val_loss: 0.0704\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0487 - val_accuracy: 0.9798 - val_loss: 0.0699\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0417 - val_accuracy: 0.9812 - val_loss: 0.0663\n",
      "Test accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the data\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to 0-1 range\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten images from 28x28 to 784\n",
    "X_train_flat = X_train.reshape(60000, 784)\n",
    "X_test_flat = X_test.reshape(10000, 784)\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile with standard settings\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_flat, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test_flat, y_test),\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(X_test_flat, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7bd7c82-17f5-4261-b091-a25f5848bd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     28\u001b[39m datagen = keras.preprocessing.image.ImageDataGenerator(\n\u001b[32m     29\u001b[39m     rotation_range=\u001b[32m10\u001b[39m,\n\u001b[32m     30\u001b[39m     zoom_range=\u001b[32m0.1\u001b[39m,\n\u001b[32m     31\u001b[39m     width_shift_range=\u001b[32m0.1\u001b[39m,\n\u001b[32m     32\u001b[39m     height_shift_range=\u001b[32m0.1\u001b[39m\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Train with augmented data\u001b[39;00m\n\u001b[32m     36\u001b[39m cnn_history = cnn_model.fit(\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mdatagen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m     38\u001b[39m     epochs=\u001b[32m15\u001b[39m,\n\u001b[32m     39\u001b[39m     validation_data=(X_test, y_test),\n\u001b[32m     40\u001b[39m     steps_per_epoch=\u001b[38;5;28mlen\u001b[39m(X_train) // \u001b[32m32\u001b[39m,\n\u001b[32m     41\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1103\u001b[39m, in \u001b[36mImageDataGenerator.flow\u001b[39m\u001b[34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow\u001b[39m(\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1091\u001b[39m     x,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1101\u001b[39m     subset=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1102\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:612\u001b[39m, in \u001b[36mNumpyArrayIterator.__init__\u001b[39m\u001b[34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[39m\n\u001b[32m    610\u001b[39m \u001b[38;5;28mself\u001b[39m.x_misc = x_misc\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.x.ndim != \u001b[32m4\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    613\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInput data in `NumpyArrayIterator` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshould have rank 4. You passed an array \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.x.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    616\u001b[39m     )\n\u001b[32m    617\u001b[39m channels_axis = \u001b[32m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data_format == \u001b[33m\"\u001b[39m\u001b[33mchannels_last\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.x.shape[channels_axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m}:\n",
      "\u001b[31mValueError\u001b[39m: Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "# CNN model for better performance\n",
    "cnn_model = keras.Sequential([\n",
    "    keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    \n",
    "    # First conv block\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second conv block\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third conv block\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Classifier\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation for better generalization\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Train with augmented data\n",
    "cnn_history = cnn_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a3e392-cf9b-4013-8d4b-15e73470146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Simple CNN in PyTorch\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "model = MNISTNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b0c3e7-7af2-47cd-acb1-dfb3b342eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load model once at startup\n",
    "model = tf.keras.models.load_model('mnist_model.h5')\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict_digit(file: UploadFile = File(...)):\n",
    "    # Read and preprocess image\n",
    "    image = Image.open(file.file).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "    image_array = np.array(image) / 255.0\n",
    "    image_array = image_array.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(image_array)\n",
    "    predicted_digit = int(np.argmax(prediction))\n",
    "    confidence = float(np.max(prediction))\n",
    "    \n",
    "    return {\n",
    "        \"digit\": predicted_digit,\n",
    "        \"confidence\": confidence,\n",
    "        \"all_probabilities\": prediction[0].tolist()\n",
    "    }\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\"status\": \"healthy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d47a769-c550-4168-a880-172f0f6fc92f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNISTNet' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m         print_memory_usage()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Use in training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m(X_train, y_train, callbacks=[MemoryCallback()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MNISTNet' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Monitor memory usage during training\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    print(f\"Memory usage: {memory_info.rss / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Add this to your training loop\n",
    "class MemoryCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print_memory_usage()\n",
    "        \n",
    "# Use in training\n",
    "model.fit(X_train, y_train, callbacks=[MemoryCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a2bb5-0dbd-443e-9195-9b5c970059dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pre-trained model as feature extractor\n",
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(28, 28, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Convert grayscale to RGB for compatibility\n",
    "def convert_to_rgb(images):\n",
    "    return np.repeat(images[..., np.newaxis], 3, axis=-1)\n",
    "\n",
    "X_train_rgb = convert_to_rgb(X_train)\n",
    "X_test_rgb = convert_to_rgb(X_test)\n",
    "\n",
    "# Build transfer learning model\n",
    "transfer_model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "base_model.trainable = False  # Freeze base model\n",
    "transfer_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c180a8a-74cd-4414-8638-0cd69ef63001",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNISTNet' object has no attribute 'call'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m converter.optimizations = [tf.lite.Optimize.DEFAULT]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Post-training quantization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tflite_quantized_model = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mmnist_quantized.tflite\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1254\u001b[39m, in \u001b[36m_export_metrics.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1251\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(convert_func)\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1253\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1206\u001b[39m, in \u001b[36mTFLiteConverterBase._convert_and_export_metrics\u001b[39m\u001b[34m(self, convert_func, *args, **kwargs)\u001b[39m\n\u001b[32m   1204\u001b[39m \u001b[38;5;28mself\u001b[39m._save_conversion_params_metric()\n\u001b[32m   1205\u001b[39m start_time = time.process_time()\n\u001b[32m-> \u001b[39m\u001b[32m1206\u001b[39m result = \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1207\u001b[39m elapsed_time_ms = (time.process_time() - start_time) * \u001b[32m1000\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1777\u001b[39m, in \u001b[36mTFLiteKerasModelConverterV2.convert\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1773\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[32m   1774\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[32m   1776\u001b[39m graph_def, input_tensors, output_tensors, frozen_func = (\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1778\u001b[39m )\n\u001b[32m   1780\u001b[39m graph_def = \u001b[38;5;28mself\u001b[39m._optimize_tf_model(\n\u001b[32m   1781\u001b[39m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[32m   1782\u001b[39m )\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m).convert(\n\u001b[32m   1785\u001b[39m     graph_def, input_tensors, output_tensors\n\u001b[32m   1786\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[39m, in \u001b[36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    214\u001b[39m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[39m, in \u001b[36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m converter_error.errors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1714\u001b[39m, in \u001b[36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1708\u001b[39m input_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1709\u001b[39m \u001b[38;5;66;03m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[32m   1710\u001b[39m \u001b[38;5;66;03m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;66;03m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;66;03m# to None.\u001b[39;00m\n\u001b[32m   1713\u001b[39m \u001b[38;5;66;03m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_keras_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m, _def_function.Function):\n\u001b[32m   1715\u001b[39m   \u001b[38;5;66;03m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[32m   1716\u001b[39m   \u001b[38;5;66;03m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[32m   1717\u001b[39m   \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[32m   1718\u001b[39m   input_signature = _model_input_signature(\n\u001b[32m   1719\u001b[39m       \u001b[38;5;28mself\u001b[39m._keras_model, keep_original_batch_size=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1720\u001b[39m   )\n\u001b[32m   1722\u001b[39m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MNISTNet' object has no attribute 'call'"
     ]
    }
   ],
   "source": [
    "# Model quantization for smaller size and faster inference\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Post-training quantization\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('mnist_quantized.tflite', 'wb') as f:\n",
    "    f.write(tflite_quantized_model)\n",
    "\n",
    "# Model pruning for sparsity\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# Apply pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruned_model = prune_low_magnitude(\n",
    "    model,\n",
    "    pruning_schedule=tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.30,\n",
    "        final_sparsity=0.80,\n",
    "        begin_step=0,\n",
    "        end_step=1000\n",
    "    )\n",
    ")\n",
    "\n",
    "pruned_model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e83e6c6e-5f87-43ca-98b8-57b37e4d0603",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MNISTNet' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     49\u001b[39m         \u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m: np.mean(predicted_classes == y_test),\n\u001b[32m     50\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minference_time_ms\u001b[39m\u001b[33m'\u001b[39m: avg_inference_time * \u001b[32m1000\u001b[39m,\n\u001b[32m     51\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mthroughput_ips\u001b[39m\u001b[33m'\u001b[39m: throughput,\n\u001b[32m     52\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel_size_mb\u001b[39m\u001b[33m'\u001b[39m: model_size_mb\n\u001b[32m     53\u001b[39m     }\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Run benchmark\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m results = \u001b[43mbenchmark_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mbenchmark_model\u001b[39m\u001b[34m(model, X_test, y_test, num_runs)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Comprehensive model benchmarking\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Accuracy metrics\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m predictions = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[32m     12\u001b[39m predicted_classes = np.argmax(predictions, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClassification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'MNISTNet' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def benchmark_model(model, X_test, y_test, num_runs=100):\n",
    "    \"\"\"Comprehensive model benchmarking\"\"\"\n",
    "    \n",
    "    # Accuracy metrics\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predicted_classes))\n",
    "    \n",
    "    # Performance metrics\n",
    "    inference_times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _ = model.predict(X_test[:100])  # Batch of 100 images\n",
    "        end_time = time.time()\n",
    "        inference_times.append(end_time - start_time)\n",
    "    \n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    throughput = 100 / avg_inference_time  # images per second\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Average inference time: {avg_inference_time*1000:.2f} ms\")\n",
    "    print(f\"Throughput: {throughput:.2f} images/second\")\n",
    "    print(f\"Latency per image: {avg_inference_time*10:.2f} ms\")\n",
    "    \n",
    "    # Model size\n",
    "    model.save('/tmp/temp_model.h5')\n",
    "    import os\n",
    "    model_size_mb = os.path.getsize('/tmp/temp_model.h5') / (1024 * 1024)\n",
    "    print(f\"Model size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Confusion matrix visualization\n",
    "    cm = confusion_matrix(y_test, predicted_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': np.mean(predicted_classes == y_test),\n",
    "        'inference_time_ms': avg_inference_time * 1000,\n",
    "        'throughput_ips': throughput,\n",
    "        'model_size_mb': model_size_mb\n",
    "    }\n",
    "\n",
    "# Run benchmark\n",
    "results = benchmark_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1ba50-7730-43ca-b483-139a9574c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow integration example\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "# Start MLflow experiment\n",
    "mlflow.set_experiment(\"mnist_experiments\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", 10)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"optimizer\", \"adam\")\n",
    "    mlflow.log_param(\"architecture\", \"cnn\")\n",
    "    \n",
    "    # Train model (your existing code here)\n",
    "    history = model.fit(X_train, y_train, \n",
    "                       epochs=10, \n",
    "                       validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Log metrics\n",
    "    final_accuracy = max(history.history['val_accuracy'])\n",
    "    mlflow.log_metric(\"accuracy\", final_accuracy)\n",
    "    mlflow.log_metric(\"val_loss\", min(history.history['val_loss']))\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.tensorflow.log_model(model, \"model\")\n",
    "    \n",
    "    # Log artifacts (plots, confusion matrices, etc.)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    mlflow.log_artifact('accuracy_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce95056-be57-4359-a32d-b447513252b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbbf3480-fa59-48a4-bbbc-db602d57521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">363</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)                  │             \u001b[38;5;34m363\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,971</span> (410.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,971\u001b[0m (410.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,971</span> (410.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,971\u001b[0m (410.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6835 - loss: 1.7414 - val_accuracy: 0.8605 - val_loss: 0.7027\n",
      "Epoch 2/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.6339 - val_accuracy: 0.8896 - val_loss: 0.5044\n",
      "Epoch 3/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.4138 - val_accuracy: 0.9190 - val_loss: 0.3566\n",
      "Epoch 4/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.3042 - val_accuracy: 0.9210 - val_loss: 0.3476\n",
      "Epoch 5/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2444 - val_accuracy: 0.9451 - val_loss: 0.2316\n",
      "Epoch 6/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1936 - val_accuracy: 0.9534 - val_loss: 0.2124\n",
      "Epoch 7/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1484 - val_accuracy: 0.9592 - val_loss: 0.1740\n",
      "Epoch 8/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1313 - val_accuracy: 0.9575 - val_loss: 0.1755\n",
      "Epoch 9/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1130 - val_accuracy: 0.9589 - val_loss: 0.1964\n",
      "Epoch 10/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.1008 - val_accuracy: 0.9572 - val_loss: 0.1810\n",
      "Epoch 11/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0947 - val_accuracy: 0.9592 - val_loss: 0.1727\n",
      "Epoch 12/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0870 - val_accuracy: 0.9507 - val_loss: 0.2325\n",
      "Epoch 13/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0826 - val_accuracy: 0.9629 - val_loss: 0.1806\n",
      "Epoch 14/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0764 - val_accuracy: 0.9690 - val_loss: 0.1529\n",
      "Epoch 15/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0728 - val_accuracy: 0.9597 - val_loss: 0.2045\n",
      "Epoch 16/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0715 - val_accuracy: 0.9632 - val_loss: 0.1783\n",
      "Epoch 17/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0659 - val_accuracy: 0.9688 - val_loss: 0.1810\n",
      "Epoch 18/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0649 - val_accuracy: 0.9691 - val_loss: 0.1840\n",
      "Epoch 19/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0632 - val_accuracy: 0.9616 - val_loss: 0.2518\n",
      "Epoch 20/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.0570 - val_accuracy: 0.9681 - val_loss: 0.1781\n",
      "Epoch 21/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0600 - val_accuracy: 0.9684 - val_loss: 0.1821\n",
      "Epoch 22/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0581 - val_accuracy: 0.9702 - val_loss: 0.1936\n",
      "Epoch 23/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0572 - val_accuracy: 0.9653 - val_loss: 0.2296\n",
      "Epoch 24/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0602 - val_accuracy: 0.9657 - val_loss: 0.2386\n",
      "Epoch 25/25\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0486 - val_accuracy: 0.9659 - val_loss: 0.2583\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14f3dde2f30>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[2])\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(11,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "history = model.fit(X_train,y_train,epochs=25,validation_split=0.2)\n",
    "\n",
    "y_prob = model.predict(X_test)\n",
    "y_pred = y_prob.argmax(axis=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709bb71a-ce0a-4bbb-ae33-c54e83387419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec53f112-ae7d-45d0-ac8b-63dfbd70d22a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (60000, 28, 28)\n",
      "Testing Data Shape: (10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2719 - val_accuracy: 0.9577 - val_loss: 0.1400\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1115 - val_accuracy: 0.9693 - val_loss: 0.1055\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9761 - loss: 0.0778 - val_accuracy: 0.9702 - val_loss: 0.0991\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0550 - val_accuracy: 0.9704 - val_loss: 0.0994\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0453 - val_accuracy: 0.9744 - val_loss: 0.0873\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0764\n",
      "Test Accuracy: 97.80%\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd        \n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"Training Data Shape: {x_train.shape}\")\n",
    "print(f\"Testing Data Shape: {x_test.shape}\")        \n",
    "\n",
    "# Display sample images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()   \n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0        \n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)        \n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),  # Hidden layer with 128 neurons\n",
    "    Dense(64, activation='relu'),                      # Hidden layer with 64 neurons\n",
    "    Dense(10, activation='softmax')                # Output layer with 10 classes (0-9)\n",
    "])       \n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")        \n",
    "\n",
    "model.summary()      \n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2) \n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")       \n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Display sample predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Pred: {np.argmax(predictions[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.show()       \n",
    "\n",
    "model.save('mnist_digit_classifier.h5')     \n",
    "\n",
    "loaded_model = tf.keras.models.load_model('mnist_digit_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac160f-12f9-444a-8be9-250ac7ca4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b02b5f5e-73d5-4b54-8c3f-baaa54fb4996",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1673913479.py, line 44)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpredicted_label = np.argmax(model.predict(np.expand_dims(test_images[index], axis=0))\u001b[39m\n                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "import random\n",
    "# Randomly select 4 indices from the test data\n",
    "random_indices = random.sample(range(len(test_images)), 4)\n",
    "\n",
    "for i, index in enumerate(random_indices):\n",
    "    image = test_images[index].reshape(28, 28)  # Reshape back to 2D\n",
    "    predicted_label = np.argmax(model.predict(np.expand_dims(test_images[index], axis=0))\n",
    "    actual_label = np.argmax(test_labels[index])\n",
    "\n",
    "    # Display the image\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_label}\\nActual: {actual_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(selected_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Actual: {true_labels[i]}\\nPredicted: {predicted_labels[i]}\")\n",
    "\n",
    "    # Plot the probability chart\n",
    "    plt.subplot(2, 4, i + 5)\n",
    "    plt.bar(range(10), model.predict(selected_images[i:i + 1])[0])\n",
    "    plt.xticks(range(10), range(10))\n",
    "    plt.xlabel(\"Digit Class\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9cd313-c1ae-4275-bb58-598887c5f3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
